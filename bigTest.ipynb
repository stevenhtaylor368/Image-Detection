{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images loaded in\n",
      "Computing Features for  car\n",
      "completed sift for car\n",
      "Computing Features for  face\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/kushalvyas/Bag-of-Visual-Words-Python/blob/master/Bag.py\n",
    "'''\n",
    "Trevor Little & Steven Taylor\n",
    "'''\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np \n",
    "from glob import glob \n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# create a dataset sample space that will be used\n",
    "# to test KMeans. Use function : make_blobs\n",
    "# \n",
    "def conversion(s):\n",
    "    m = s // 60\n",
    "    s = s % 60\n",
    "    h = m // 60\n",
    "    m = m % 60\n",
    "    print(\"Total Run Time= {0}:{1}:{2}\".format(int(h),int(m),s))\n",
    "    \n",
    "class ImageHelpers:\n",
    "\tdef __init__(self):\n",
    "\t\tself.sift_object = cv2.SIFT_create()\n",
    "\tdef gray(self, image):\n",
    "\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\treturn gray\n",
    "\n",
    "\tdef features(self, image):\n",
    "\t\tkeypoints, descriptors = self.sift_object.detectAndCompute(image, None)\n",
    "\t\treturn [keypoints, descriptors]\n",
    "\n",
    "\n",
    "class BOVHelpers:\n",
    "\tdef __init__(self, n_clusters = 75):\n",
    "\t\tself.n_clusters = n_clusters\n",
    "\t\tself.kmeans_obj = KMeans(n_clusters = n_clusters)\n",
    "\t\tself.kmeans_ret = None\n",
    "\t\tself.descriptor_vstack = None\n",
    "\t\tself.mega_histogram = None\n",
    "\t\tself.clf  = SVC()\t\n",
    "\n",
    "\tdef cluster(self):\n",
    "\t\t\"\"\"\t\n",
    "\t\tcluster using KMeans algorithm, \n",
    "\t\t\"\"\"\n",
    "\t\tself.kmeans_ret = self.kmeans_obj.fit_predict(self.descriptor_vstack)\n",
    "\n",
    "\tdef developVocabulary(self,n_images, descriptor_list, kmeans_ret = None):\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\tEach cluster denotes a particular visual word \n",
    "\t\tEvery image can be represeted as a combination of multiple \n",
    "\t\tvisual words. The best method is to generate a sparse histogram\n",
    "\t\tthat contains the frequency of occurence of each visual word \n",
    "\t\tThus the vocabulary comprises of a set of histograms of encompassing\n",
    "\t\tall descriptions for all images\n",
    "\t\t\"\"\"\n",
    "\t\tself.mega_histogram = np.array([np.zeros(self.n_clusters) for i in range(n_images)])\n",
    "\t\told_count = 0\n",
    "\t\tfor i in range(n_images):\n",
    "\t\t\tl = len(descriptor_list[i])  \n",
    "\t\t\tfor j in range(l):\n",
    "\t\t\t\tif kmeans_ret is None:\n",
    "\t\t\t\t\tidx = self.kmeans_ret[old_count+j]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tidx = kmeans_ret[old_count+j]\n",
    "\t\t\t\tself.mega_histogram[i][idx] += 1\n",
    "\t\t\told_count += l\n",
    "\t\tprint (\"Vocabulary Histogram Generated\")\n",
    "\n",
    "\tdef standardize(self, std=None):\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tstandardize is required to normalize the distribution\n",
    "\t\twrt sample size and features. If not normalized, the classifier may become\n",
    "\t\tbiased due to steep variances.\n",
    "\t\t\"\"\"\n",
    "\t\tif std is None:\n",
    "\t\t\tself.scale = StandardScaler().fit(self.mega_histogram)\n",
    "\t\t\tself.mega_histogram = self.scale.transform(self.mega_histogram)\n",
    "\t\telse:\n",
    "\t\t\tprint (\"STD not none. External STD supplied\")\n",
    "\t\t\tself.mega_histogram = std.transform(self.mega_histogram)\n",
    "\n",
    "\tdef formatND(self, l):\n",
    "\t\t\"\"\"\t\n",
    "\t\trestructures list into vstack array of shape\n",
    "\t\tM samples x N features for sklearn\n",
    "\t\t\"\"\"\n",
    "\t\tvStack = np.array(l[0])\n",
    "\t\tfor remaining in l[1:]:\n",
    "\t\t\tvStack = np.vstack((vStack, remaining))\n",
    "\t\tself.descriptor_vstack = vStack.copy()\n",
    "\t\treturn vStack\n",
    "\n",
    "\tdef train(self, train_labels):\n",
    "\t\t\"\"\"\n",
    "\t\tuses sklearn.svm.SVC classifier (SVM) \n",
    "\t\t\"\"\"\n",
    "\t\tprint (\"Training SVM\")\n",
    "\t\tprint (self.clf)\n",
    "\t\tself.clf.fit(self.mega_histogram, train_labels)\n",
    "\t\tprint (\"Training completed\")\n",
    "\n",
    "\tdef predict(self, iplist):\n",
    "\t\tpredictions = self.clf.predict(iplist)\n",
    "\t\treturn predictions\n",
    "\n",
    "\tdef plotHist(self, vocabulary = None):\n",
    "\t\tprint (\"Plotting histogram\")\n",
    "\t\tif vocabulary is None:\n",
    "\t\t\tvocabulary = self.mega_histogram\n",
    "\t\tprint(\"clusters\", self.n_clusters)\n",
    "\t\tx_scalar = np.arange(self.n_clusters)\n",
    "\t\ty_scalar = np.array([abs(np.sum(vocabulary[:,h], dtype=np.int32)) for h in range(self.n_clusters)])\n",
    "\t\t#print (y_scalar)\n",
    "\t\tplt.bar(x_scalar, y_scalar)\n",
    "\t\tplt.xlabel(\"Visual Word Index\")\n",
    "\t\tplt.ylabel(\"Frequency\")\n",
    "\t\tplt.title(\"Complete Vocabulary Generated\")\n",
    "\t\tplt.xticks(x_scalar + 0.4, x_scalar)\n",
    "\t\tplt.show()\n",
    "\n",
    "class FileHelpers:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def getFiles(self, path):\n",
    "        \"\"\"\n",
    "        - returns  a dictionary of all files \n",
    "        having key => value as  objectname => image path\n",
    "        - returns total number of files.\n",
    "        \"\"\"\n",
    "\n",
    "        imlist = {}\n",
    "        count = 0\n",
    "        for each in glob(path + \"*\"):\n",
    "            x = each.split(\"\\\\\")[-1]\n",
    "            word = x.strip()\n",
    "            imlist[word] = []\n",
    "            imgDir =  path + word + \"\\\\\"\n",
    "            data_path = os.path.join(imgDir,'*.jpg') \n",
    "            files = glob(data_path)\n",
    "            for imagefile in files:\n",
    "                im = cv2.imread(imagefile, 0)\n",
    "                normalized = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                imlist[word].append(normalized)\n",
    "                count +=1 \n",
    "        print(\"images loaded in\")\n",
    "        return [imlist, count]\n",
    "\n",
    "        \n",
    "        \n",
    "class BOV:\n",
    "    def __init__(self, no_clusters):\n",
    "        self.no_clusters = no_clusters\n",
    "        self.train_path = None\n",
    "        self.test_path = None\n",
    "        self.im_helper = ImageHelpers()\n",
    "        self.bov_helper = BOVHelpers(no_clusters)\n",
    "        self.file_helper = FileHelpers()\n",
    "        self.images = None\n",
    "        self.trainImageCount = 0\n",
    "        self.train_labels = np.array([])\n",
    "        self.name_dict = {}\n",
    "        self.descriptor_list = []\n",
    "\n",
    "    def trainModel(self):\n",
    "        \"\"\"\n",
    "        This method contains the entire module \n",
    "        required for training the bag of visual words model\n",
    "        Use of helper functions will be extensive.\n",
    "        \"\"\"\n",
    "        # read file. prepare file lists.\n",
    "        self.images, self.trainImageCount = self.file_helper.getFiles(self.train_path)\n",
    "        # extract SIFT Features from each image\n",
    "        label_count = 0 \n",
    "        for word, imlist in self.images.items():\n",
    "            self.name_dict[str(label_count)] = word\n",
    "            print (\"Computing Features for \", word)\n",
    "            for im in imlist:\n",
    "                self.train_labels = np.append(self.train_labels, label_count)\n",
    "                kp, des = self.im_helper.features(im)\n",
    "                self.descriptor_list.append(des)\n",
    "            print(\"completed sift for\", word)\n",
    "            label_count += 1\n",
    "        start_time = time.time()\n",
    "        # perform clustering\n",
    "        print(\"Computing stack\")\n",
    "        bov_descriptor_stack = self.bov_helper.formatND(self.descriptor_list)\n",
    "        print(\"descriptor complete\")\n",
    "        self.bov_helper.cluster()\n",
    "        end_time = time.time()\n",
    "        runtime = end_time - start_time\n",
    "        conversion(runtime)\n",
    "        print(\"K clustering done\")\n",
    "        self.bov_helper.developVocabulary(n_images = self.trainImageCount, descriptor_list=self.descriptor_list)\n",
    "        self.bov_helper.standardize()\n",
    "        self.bov_helper.train(self.train_labels)\n",
    "\n",
    "\n",
    "    def recognize(self,test_img, test_image_path=None):\n",
    "        \"\"\" \n",
    "        This method recognizes a single image \n",
    "        It can be utilized individually as well.\n",
    "        \"\"\"\n",
    "        kp, des = self.im_helper.features(test_img)\n",
    "        vocab = np.array( [[ 0 for i in range(self.no_clusters)]])\n",
    "        test_ret = self.bov_helper.kmeans_obj.predict(des)\n",
    "        for each in test_ret:\n",
    "            vocab[0][each] += 1\n",
    "\n",
    "        vocab = self.bov_helper.scale.transform(vocab)\n",
    "        lb = self.bov_helper.clf.predict(vocab)     \n",
    "        return lb\n",
    "\n",
    "\n",
    "\n",
    "    def testModel(self):\n",
    "        \"\"\" \n",
    "        This method is to test the trained classifier\n",
    "        read all images from testing path \n",
    "        use BOVHelpers.predict() function to obtain classes of each image\n",
    "        \"\"\"\n",
    "        self.testImages, self.testImageCount = self.file_helper.getFiles(self.test_path)\n",
    "        predictions = []\n",
    "        for word, imlist in self.images.items():\n",
    "            print (\"processing \" ,word)\n",
    "            for im in imlist:\n",
    "                cl = self.recognize(im)\n",
    "                predictions.append({\n",
    "                    'image':im,\n",
    "                    'class':cl,\n",
    "                    'object_name':self.name_dict[str(int(cl[0]))]\n",
    "                    })\n",
    "        pcnt = 0 \n",
    "        fcnt = 0 \n",
    "        mcnt = 0 \n",
    "        ccnt = 0 \n",
    "        lcnt = 0\n",
    "        count = 0 \n",
    "        f = open(\"Images\\outputImg.txt\", \"a\")\n",
    "        for each in predictions:\n",
    "            path = self.test_path + each['object_name'] + '\\\\'\n",
    "            filenamePrefix = ''\n",
    "            if each['object_name'] == \"car\":\n",
    "                filenamePrefix = 'C'\n",
    "                cv2.imwrite(path + filenamePrefix +str(ccnt) + each['object_name'] + '.jpg', each['image'])\n",
    "                ccnt = ccnt + 1 \n",
    "            elif each['object_name'] == \"plane\":\n",
    "                filenamePrefix = 'A'\n",
    "                cv2.imwrite(path + filenamePrefix +str(pcnt) + each['object_name'] + '.jpg', each['image'])\n",
    "                pcnt = pcnt + 1\n",
    "            elif each['object_name'] == \"motorcycle\":\n",
    "                filenamePrefix = 'M'\n",
    "                cv2.imwrite(path + filenamePrefix +str(mcnt) + each['object_name'] + '.jpg', each['image'])\n",
    "                mcnt = mcnt + 1\n",
    "            elif each['object_name'] == \"face\":\n",
    "                filenamePrefix = 'F'\n",
    "                cv2.imwrite(path + filenamePrefix +str(fcnt) + each['object_name'] + '.jpg', each['image'])\n",
    "                fcnt = fcnt + 1\n",
    "            else:\n",
    "                filenamePrefix = 'L'\n",
    "                cv2.imwrite(path + filenamePrefix +str(lcnt) + each['object_name'] + '.jpg', each['image'])\n",
    "                lcnt = lcnt + 1\n",
    "            f.write(\"Image: %s,\\n\" % str(each['image']))\n",
    "            f.write(\"Classified as: %s \\n\" % each['object_name'])\n",
    "            plt.imshow(cv2.cvtColor(each['image'], cv2.COLOR_GRAY2RGB))\n",
    "            plt.title(each['object_name'])\n",
    "            plt.show()\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    def print_vars(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    train_path = 'Images/minTrain/'\n",
    "    test_path = 'Images/minTest/' \n",
    "    start_time = time.time()\n",
    "    bov = BOV(no_clusters=75)\n",
    "    # set training path\n",
    "    bov.train_path = train_path\n",
    "    # set output path\n",
    "    bov.test_path = test_path\n",
    "    # train the model\n",
    "    bov.trainModel()\n",
    "    print(\"completed training\")\n",
    "    # test model\n",
    "    bov.testModel()\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    conversion(runtime)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
